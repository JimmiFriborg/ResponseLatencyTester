# Hardware Latency Tester v4.0 Implementation Plan

This plan outlines a 30-day (4–6 week) delivery program that transforms the latency tester from a raw data utility into a full production workflow. Each phase builds on the previous one, culminating in a tool that rivals professional video analysis suites while remaining portable as a single-file web app.

## Delivery Overview
- **Total duration:** 30 calendar days (target 4–6 weeks including buffer)
- **Cadence:** 8 sequential phases with optional overlap where dependencies allow
- **Teams:** Core engineering (media, UI, automation), QA, and documentation
- **Key milestones:** Video playback foundation, manual markers, audio waveform, pattern recognition, hardware management, video-linked execution, export polish, testing & launch

## Phase Breakdown

### Phase 1 (Days 1–3): Video Player Foundation
- Embed HTML5 video player with precise frame stepping (supports 30/60/120 FPS)
- Implement keyboard controls: Space (play/pause), J/K/L (scrub), ←/→ (frame step)
- Build master timeline model with timecode formatting (HH:MM:SS:FF)
- Persist playback rate, zoom level, and loop range in local storage for continuity
- Acceptance: Reviewer can scrub to an exact frame, pause, and resume without desync across reloads

### Phase 2 (Days 4–7): Manual Markers
- Create zoomable timeline canvas aligned with master timebase
- Support click-to-add markers with drag-to-adjust handles and snapping
- Introduce marker inspector for editing metadata (label, axis, category, notes)
- Provide sortable marker list with keyboard navigation and bulk delete
- Enable CSV export compatible with DaVinci Resolve marker imports
- Acceptance: User can import a video, annotate with markers, edit details, and export back to CSV

### Phase 3 (Days 8–10): Audio Waveform Integration
- Integrate WaveSurfer.js for audio waveform rendering and syncing with video playback
- Overlay markers on waveform and provide zoom/pan controls shared with the video timeline
- Cache decoded waveform data in IndexedDB to accelerate repeated loads of large videos
- Expose mute/solo controls per channel to isolate key signals (e.g., click vs. beep)
- Acceptance: Waveform remains in lockstep with video timeline while scrubbing and zooming

### Phase 4 (Days 11–15): Pattern Recognition
- Build template training workflow: select a region, label sub-events, and save as pattern template
- Extract audiovisual signatures using Web Audio API FFT and frame differencing
- Implement auto-detection pipeline that scans for patterns and returns confidence scores
- Provide review interface for detections with accept/reject and inline adjustments
- Maintain pattern library with versioning and sharing between projects
- Acceptance: Given a trained template, the system auto-populates candidate markers with confidence annotations

### Phase 5 (Days 16–18): Hardware Management
- Introduce hardware profile CRUD (create, duplicate, archive) with Tag type, revision, firmware, and accessories
- Associate profiles with test cases and store requirement presets per profile
- Surface hardware differences in comparison views, enabling quick context switching
- Track firmware history and flag mismatches between execution hardware and expected profile
- Acceptance: Reviewer sees correct hardware + requirement pairings per test case, with change history

### Phase 6 (Days 19–21): Video-Linked Execution
- Capture video frame thumbnails for each marker and embed within execution reports
- Provide clip extraction (start/end time selection) for sharing focused segments
- Enhance PDF export to include embedded frames and context metadata
- Wire up shareable execution packages containing video references, markers, and hardware context
- Acceptance: Execution report shows inline media evidence and exports maintain links to source frames

### Phase 7 (Days 22–25): Export & Polish
- Ship multi-format export suite (CSV, JSON, PDF) with configurable columns and localization-ready strings
- Add optional annotated video generation using FFmpeg.wasm (gated via build flag due to 30 MB payload)
- Optimize performance (memoization, virtualized lists, lazy waveform loading) and add dark mode theme
- Deliver end-user documentation and quickstart guides covering new workflows
- Acceptance: Exports align with stakeholder needs, UI feels responsive under large datasets, docs published

### Phase 8 (Days 26–30): Testing & Release
- Run cross-browser validation (Chrome, Edge, Firefox, Safari) with regression checklist
- Conduct performance benchmarking against large sample projects (multi-GB videos, 500+ markers)
- Facilitate user acceptance testing with pilot teams, capturing feedback and final tweaks
- Prepare launch artifacts: release notes, announcement, onboarding walkthrough
- Acceptance: All critical bugs resolved, stakeholders sign off on release readiness

## Dependencies & Sequencing
- Phase 1 must complete before marker, waveform, and pattern work (establishes media engine)
- Phase 2 manual markers supply training data and UI scaffolding required in Phase 4
- Phase 3 waveform data feeds into pattern recognition FFT routines
- Phase 5 hardware management depends on marker and pattern schemas to link requirements
- Export enhancements (Phase 7) rely on assets generated in Phases 2–6

## Resource Allocation
- **Media/Frontend Engineer:** Leads Phases 1–4, supports 6–7
- **Data/Algorithm Engineer:** Focuses on Phase 4 detection pipeline, advises on FFT accuracy
- **Full-stack Engineer:** Owns Phase 5 management UI, Phase 6 execution packaging, and export backend glue
- **QA Specialist:** Embedded from Phase 3 onwards; drives Phase 8 test execution
- **Technical Writer:** Drafts documentation during Phase 7, finalizes for launch in Phase 8

## Risk Management
- **Heavy bundle size (FFmpeg.wasm):** Ship as optional add-on; default build excludes it to keep ~150 KB baseline
- **Pattern accuracy:** Establish quality gates (min confidence, manual verification) before auto-applying markers
- **Large file handling:** Use streaming APIs and IndexedDB caching to avoid memory pressure on >2 GB videos
- **Timeline slip:** Buffer weekends for catch-up and hold daily standups focused on blocker resolution

## Success Metrics
- 95% of executions carry linked hardware profiles and requirement presets
- Automated pattern detection reduces manual marker entry time by 60%
- Exported PDF with frames accepted by compliance reviewers without manual edits
- Pilot teams report ≥4.5/5 satisfaction on workflow survey post-launch

## Outstanding Questions for Stakeholders
1. **Timeline acceptance:** Is the 4–6 week window aligned with release expectations?
2. **Phase prioritization:** Should any phases be pulled forward (e.g., hardware management) due to external dependencies?
3. **Video format support:** Are formats beyond MP4/H.264 (e.g., MOV, AVI, WebM) required for v4.0 launch?
4. **Typical asset sizes:** What is the expected upper bound for video length/size to validate caching strategies?
5. **Pattern complexity:** How many distinct marker patterns per hardware type should the template library support initially?
6. **Export priorities:** Which export format (PDF, CSV, JSON, annotated video) is most critical for day-one adoption?
7. **FFmpeg.wasm appetite:** Should we commit to the 30 MB payload for annotated video export in v4.0, or defer to v4.1?

Stakeholder feedback on these questions will shape scope trade-offs and sequencing before implementation begins.
