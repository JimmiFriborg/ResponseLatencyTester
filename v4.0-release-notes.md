# Hardware Latency Tester v4.0

## ðŸš€ Highlights
- **Per-event Axis Entry** â€“ Axis and direction can now be captured for every timestamp without grouping. This enables chronological editing while still surfacing the axis context in summaries.
- **Axis Performance Dashboards** â€“ Execution and comparison views include per-axis statistics (min/avg/max, pass rate, event counts) so teams can benchmark motion directions side-by-side.
- **Test Case Hardware & Requirements** â€“ Each test case stores dedicated hardware assignments and requirement profiles, ensuring environment context and thresholds travel with exported data.
- **Comparison Intelligence** â€“ Summary comparisons surface requirement sources and latencies, while a new axis comparison matrix contrasts each execution across every recorded axis.
- **Persistence & Normalization** â€“ Imports are normalized with defaults for hardware, requirements, and axis ranges to remain compatible with earlier saves.

## âœ… Evaluation
- **Axis visibility:** Requirements for ungrouped axes are met; axis tables in both execution and comparison views expose comparable metrics for every direction.
- **Configuration parity:** Hardware and requirement editors live in the Settings view, with execution cards reflecting the assigned context so reviewers see the same information.
- **Data integrity:** Normalization fills missing fields on load/import, preventing legacy datasets from breaking the new UX.
- **Pass/Fail clarity:** Test case-level requirements override execution criteria, and the UI clearly communicates the active threshold in statistics and comparison tables.

Upgrade to v4.0 to streamline analysis workflows and keep test context at the center of every report.

For the full program of work that delivered these capabilities, refer to the accompanying [v4.0 implementation plan](./v4.0-implementation-plan.md).
